# 人工智慧導論

## CH1 Introduction
AI定義(不同類別):<br>
a. 思考面:
>1. AI需要以人類方式思考
>2. 需要以一定方式思考，解決問題即可算是AI

b. 行為面:
>1. 活動行為需要像是人類
>2. 只要能夠實際解決問題(不論移動方式)
-------------------------------------------
## CH2 Intelligent Agents
* Agents -> 任何可以藉由sensor感知環境，並且藉由actuators互動的原件
* Rational agent -> 在所有可能性中，選擇最佳解的主體，由於在rational agent的觀點上並非全知觀點，因此我們期望rational agent有學習的能力，從現有資料中學習以選擇最佳解
* agent = architecture + program

> simple reflex agents <br>
> ![](https://i.imgur.com/AWydUKP.png)
> * 單純以現有環境資料作為決策的依據

>Model-based reflex agent
>![](https://i.imgur.com/hNEOcRW.png)
>* work in a partially observable environment, and track the situation.
>* 兩個在models-based reflex agent中重要的部分:
>&emsp;1.Model: It is knowledge about "how things happen in the world," so it is called a Model-based agent.
&emsp;2.Internal State: It is a representation of the current state based on percept history.

>Goal-based agents
>![](https://i.imgur.com/EzcZFoo.png)
>* The knowledge of the current state environment is not always sufficient to decide for an agent to what to do.
>需要有最終目標，而非給予規則，由目標選擇達到目標的作法

>Utility-based Reflex Agents
>![](https://i.imgur.com/EjKbkYF.png)
>* 類似Goal-based agents 
>* 作法並非單純達到目標，而是能夠最佳的達到目標
>* 會將每個狀態轉換成數值，以觀看達到目標的效能

>Learning Agents
>![](https://i.imgur.com/janx8lg.png)
>能藉由過往經驗學習
>A learning agent has mainly four conceptual components, which are:<br>
1.Learning element: It is responsible for making improvements by learning from environment<br>
2.Critic: Learning element takes feedback from critic which describes that how well the agent is doing with respect to a fixed performance standard.<br>
3.Performance element: It is responsible for selecting external action<br>
4.Problem generator: This component is responsible for suggesting actions that will lead to new and informative experiences.
-------------------------------------------

## CH3 Solving Problems by Searching

* Introduction of Problem-solving agent(one kind of goal-based agent)

&emsp; A problem can gradually defined by five part
1. Initial state (最初始的狀態)
2. posible action (可能採取動作)
3. description of each action does(transition model -闡述這個action的執行，例如result(initial state,action)= next state )
4. goal test/goal state(目標狀態)

後續以下圖問題作為範例:
![](https://i.imgur.com/UMAkwOB.png)

Searching Alogorithms 
-> searching tree 
![](https://i.imgur.com/Dqoj66c.png)

在樹上的節點N，包含四個結構分別如下:
1. n.state - 當節點的狀態
2. n.parent - n節點的上一層節點狀態
3. n.action - parent 執行甚麼動作達current node 
4. n.Path-Cost - denoted by g(n)，path cost between the initial state and current(初始到現在節點的損失)

**Uninformed Search Strategies**
- 策略沒有關於問題定義的額外資訊，因此使用目標導向。

### Beadth-first search(BFS)
&emsp;同層節點完全展開，在確定該層節點沒有目標解，才會進入到下一層的節點
![](https://i.imgur.com/sR7UbJ1.png)

>&emsp;在假設每層上有b個節點時，展開到第d層所需展開節點數量為
sum(b^n^(n:1->d))，由此可見其時間與空間複雜度為O(b^d^)

### Uniform-cost search
&emsp;由最小損失路徑(min(g(n))為目標，逐次展開節點
![](https://i.imgur.com/3JgvQog.png)

>&emsp;假設C'為最佳損失(最小)，且每個步驟損失最少為e，則此方法的時間與空間複雜度為O(b^1+(C'/e)^)

### Depth-first search(DFS)
&emsp;先鎖定單個節點，並且將其朝向單一方向展開至最深層，若沒有找到目標解，再逐層往回回推
![](https://i.imgur.com/LWL26bx.png)
>&emsp;其時間複雜度為O(b^m^)，當中m為最深深度，因此m可能相較於BFS當中的d要大很多，空間複雜度為O(bm)，因此在設計上可藉由指定深度減少空間以及時間複雜度。

### Iterative deepening DFS 
&emsp;每次疊代增加深度，但當次疊代的找尋方法同DFS，這樣的好處是，當深度為m，但解答在n層就出現時(n<m)，則可在第n次疊代就藉由DFS的方式找到，而不需要直接搜尋到第m層，能夠有效減少複雜度
![](https://i.imgur.com/YQDJzPe.png)
>雖然疊代會產生一定的計算量，但與直接利用DFS找尋到m層來說，以疊代的方式找尋到n層還是可以有效減少複雜度，主要是因為在時間複雜度上是以次方方式增長

### bidirection search 
&emsp;只有兩種選擇方案的搜尋方式，因此並非每種狀況皆可使用。

**Informed (Heuristic) Search Strategies**
&emsp;可得知距離初始狀態距離，並且藉由啟發函數推算距離目標距離，並依造評估函數f(n)，決定要展開哪個節點，進而增加效率。
- heuristic function, denoted as h(n)
> h(n) = estimated cost of the cheapest path from the state at node n to a goal state.

### Greedy best-first search 
&emsp;展開最接近目標的節點，單純使用heuristic作為預估。
![](https://i.imgur.com/EUgLafG.png)

![](https://i.imgur.com/XUQpSme.png)
然而，此方法未必是最佳解。

### A^*^ search
&emsp;利用到達現節點的損失函數g(n)，以及預估到達目標的損失函數h(n)，則f(n)=g(n)+h(n)

&emsp;當使用A^*^ search要達到最佳解時，須符合兩個情況分別為:admissibility(可受理性) and consistency(一致性)

* admissibility ->要求h(n)必須為admissible heuristic，代表此方程式在預估到達目標的損失時，必須不會高估損失(預估的損失必定小於或等於真實損失)
* consistent(monotonicity) -> 假定現今節點為n，而經過action a 到節點n'後，則h(n)與h(n')間有關係式:<br><img src='https://i.imgur.com/PeAQGlG.png' style ='width:200px;margin-left:150px'><br>上式當中，c代表由n採取狀態到n'中損失的距離，此式等同於三角不等式(可用向量思考)。
A^*^ search 總範例如下:
![](https://i.imgur.com/5F02BLf.png)
![](https://i.imgur.com/3RYV7W9.png)

-------------------------------------------
## CH4 Search in Complex Environments

### Local Search
![](https://i.imgur.com/AkQvjP3.png)

### Hill Climbing Search 
&emsp;一種演算法，會重複迴圈並且每圈迴圈不斷增加值(與鄰居點比較，每次接往比現值高的方向前進)，直到找到頂點，然而此種每次接往較高點前進的方法約只能解決14%問題(達到全域最大值)，但若每次前進並非要求增加，而是允許朝同值方向前進，則可能由14%增加至94%。
Hill Climbing Search 又可分為下列幾種:
* Stochastic hill climbing(鄰近點選較優點，該點未必為最佳點)
* First-choice hill climbing (選擇最接近現點的較佳解，該點未必為最佳點)
* Random-restart hill climbing 

### Simulated Annealing 
&emsp;允許出現選擇較差點的選項，但每次選擇較差點的機率會隨疊代下降(T)，而當delta(E)>0，則為較佳解，一定前進，若<0，則為較差解，每次疊代有e^delta(E)/T^的機率選擇。
![](https://i.imgur.com/x8pN2YE.png)
>每次疊代，溫度(T)會下降，因為不希望再多次疊帶後，還有相同的機率，取到較差的結果點

### Local Beam Search
&emsp;每次展開K個點，並且在該K個點內搜尋目標點，若沒有目標點，則會從從中選擇K個最佳選擇器，並依此重複展開K個點
<img src = 'https://i.imgur.com/LEWecBE.png' width ="350">
### Genetic Algorithms
&emsp;初始時有N個序列，在依造正確率作排序，於排序後兩兩序列為一組，切分序列並做交互替換(crossover)，產生新的序列，並且依照突變率隨機改變序列內容，以此作為下一次預測模型。
![](https://i.imgur.com/6eSRccn.png)
>大原則隨機切分，但是在不同領域跟應用上，可能可以在crossover上給定限制<br>

-------------------------------------------
## ch12 Quantifying Uncertainty
&emsp;在描述問題上，若是由果導因可能會需要列出無限種可能性，例如:
>Toothache =>Cavity V GumProblem...

&emsp;因此可嘗試由因導果的方式描述問題，例如:
>Cavity => Toothache

&emsp;然而在上述的例子內，也並非完全正確，因為未必所有蛀牙皆會造成牙痛的情形，因此由機率表示未失為一個好方法。

&emsp;決策理論 = 機率理論+效用理論，在決策理論的核心概念為，**只有當選擇的行為擁有最高的預測效用，且平均超過所有行動的可能結果，才視為agent為合理的**，此原則稱為最大預測效用(MSE => maximum expected utility)

**驗前機率:該機率與其餘機率無關**<br>
**驗後機率:該機率建構於另一機率之上，因此需先算另一機率才可得出該機率**<br>
### 貝氏定理
<img src = 'https://i.imgur.com/v9nLcMG.png' width = '200'><br>
上式代表，當發生b的情況下同時發生a的機率，因此藉由數學運算可得:
<img src = 'https://i.imgur.com/f7KzGVQ.png' width = '200'><br>
&emsp;在機率表示內，細體字的P代表單一情況發生的機率，
粗體字的**P**代表所有情況所形成的機率向量，例如:
> **P**(X|Y) =**P**(X=x~i~|Y=y~i~)<br>
代表列出i,j形成的二維向量，當中包含i,j各種情況的機率

**P**(A,B)代表的是結合A,B兩種情況的所有可能性，稱為joint probability distribution。以下以A為天氣，B為蛀牙，天氣內有四種情況而蛀牙有兩種情況作為舉例:<br>
<img src = 'https://i.imgur.com/frqIS9t.png' width = '450'><br>
則其展開式為:<br>
<img src = 'https://i.imgur.com/bu57r6q.png' width = '400'><br>
>註解:在機率表示式內，如果開頭是大寫則是當中的所有可能，小寫則是確定情況，例如Cavity代表的是有蛀牙以及沒蛀牙兩種情況，cavity代表的是只有蛀牙的情況<br>

聯集表示法:
>P(a ∨ b) = P(a) + P(b) − P(a ∧ b)

正常化法->當今天要計算交集機率時，可以使用兩者的joint probability，並使用正常化得出，而不需要得到母體的機率，例如:<br>
<img src = 'https://i.imgur.com/cc3iEMG.png' width = '500'><br>
上式代表今天已知牙痛，且欲求到牙痛且蛀牙的機率，或牙痛沒蛀牙，則可能性分為:<br>
1.牙痛、蛀牙且被探針偵測 <br>
2.牙痛、蛀牙且沒被探針偵測<br>
3.牙痛、沒蛀牙且被探針偵測 <br>
4.牙痛、沒蛀牙且沒被探針偵測<br>
因此可表示兩個1x2矩陣。
#### Bayes' Rule 
**P**(a|b) =**P**(a^b)**P**(b)，則由此關係是可得到:<br>
>**P**(b|a) = **P**(a^b)**P**(b)/**P**(a)<br>

此關係式及為Bayes' Rule，若以joint probability角度改寫，則為以下:<br>
><img src = 'https://i.imgur.com/aGTQ8RC.png' width = '200'><br>
>This formula shows that we have some occasion to use more general version conditionalized on some background evidence e.

&emsp;Bayes' Rule在一般的情況下看似沒用，但其實在應用上有很大的公用，例如今天得知一疾病與伴隨特定症狀的機率，且有該疾病的發生機率，以及該症狀的單獨發生機率，則可利用Bayes' Rule反推出出現該症狀時罹患疾病的機率。

Bayes' Rule應用如下:
><img src = 'https://i.imgur.com/xQhCfXL.png' width = '400'><br>
>上式中的等號左邊代表找尋牙痛且被探針搜尋到的情況下，有蛀牙以及沒蛀牙的個別機率，等號右邊為利用Bayes' Rule尋找交集部分後，再利用normalized將機率兩者形成互補為1。


































